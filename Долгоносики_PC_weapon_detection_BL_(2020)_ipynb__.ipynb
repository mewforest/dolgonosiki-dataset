{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubUsE7qtMWfj"
   },
   "source": [
    "## DOLGONOSIK PC EDITION [2020]\n",
    "\n",
    "### **Inroduction**:\n",
    "\n",
    "\n",
    "Aiming to minimize police response time by detecting weapons in a live cctv camera. The main motivation of this project is due to the increasing number of school mass shootings in the U.S.\n",
    "\n",
    "\n",
    "### This notebook is a part of this [medium post](https://medium.com/@alaasinjab/detailed-tutorial-build-your-custom-real-time-object-detector-5ade1017fd2d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65t7YUhnzDCE"
   },
   "source": [
    "## Weapon Detection Using Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv3Zm042QGJy"
   },
   "source": [
    "## Installing Required Packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation on Windows - [source](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/tensorflow-1.14/install.html)\n",
    "\n",
    "**MUST** be installed:\n",
    "- Python 3.7 (64bit) (PATH)\n",
    "- Git (PATH)\n",
    "- 7zip (PATH)\n",
    "- jupiter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                Version            \n",
      "---------------------- -------------------\n",
      "absl-py                0.11.0             \n",
      "argon2-cffi            20.1.0             \n",
      "astor                  0.8.1              \n",
      "astunparse             1.6.3              \n",
      "async-generator        1.10               \n",
      "attrs                  20.3.0             \n",
      "backcall               0.2.0              \n",
      "bleach                 3.2.1              \n",
      "cached-property        1.5.2              \n",
      "cachetools             4.2.0              \n",
      "certifi                2020.12.5          \n",
      "cffi                   1.14.4             \n",
      "chardet                4.0.0              \n",
      "colorama               0.4.4              \n",
      "contextlib2            0.6.0.post1        \n",
      "cycler                 0.10.0             \n",
      "Cython                 0.29.21            \n",
      "decorator              4.4.2              \n",
      "defusedxml             0.6.0              \n",
      "entrypoints            0.3                \n",
      "flatbuffers            1.12               \n",
      "gast                   0.4.0              \n",
      "google-auth            1.24.0             \n",
      "google-auth-oauthlib   0.4.2              \n",
      "google-pasta           0.2.0              \n",
      "grpcio                 1.34.0             \n",
      "h5py                   3.1.0              \n",
      "idna                   2.10               \n",
      "importlib-metadata     3.3.0              \n",
      "ipykernel              5.4.2              \n",
      "ipython                7.19.0             \n",
      "ipython-genutils       0.2.0              \n",
      "ipywidgets             7.5.1              \n",
      "jedi                   0.17.2             \n",
      "Jinja2                 2.11.2             \n",
      "jsonschema             3.2.0              \n",
      "jupyter                1.0.0              \n",
      "jupyter-client         6.1.7              \n",
      "jupyter-console        6.2.0              \n",
      "jupyter-core           4.7.0              \n",
      "jupyterlab-pygments    0.1.2              \n",
      "Keras-Applications     1.0.8              \n",
      "Keras-Preprocessing    1.1.2              \n",
      "kiwisolver             1.3.1              \n",
      "lvis                   0.5.3              \n",
      "lxml                   4.6.2              \n",
      "Markdown               3.3.3              \n",
      "MarkupSafe             1.1.1              \n",
      "matplotlib             3.3.3              \n",
      "mistune                0.8.4              \n",
      "nbclient               0.5.1              \n",
      "nbconvert              6.0.7              \n",
      "nbformat               5.0.8              \n",
      "nest-asyncio           1.4.3              \n",
      "notebook               6.1.5              \n",
      "numpy                  1.19.4             \n",
      "oauthlib               3.1.0              \n",
      "object-detection       0.1                \n",
      "opencv-python          4.4.0.46           \n",
      "packaging              20.8               \n",
      "pandas                 1.1.5              \n",
      "pandocfilters          1.4.3              \n",
      "parso                  0.7.1              \n",
      "pickleshare            0.7.5              \n",
      "Pillow                 8.0.1              \n",
      "pip                    19.0.3             \n",
      "prometheus-client      0.9.0              \n",
      "prompt-toolkit         3.0.8              \n",
      "protobuf               3.14.0             \n",
      "pyasn1                 0.4.8              \n",
      "pyasn1-modules         0.2.8              \n",
      "pycparser              2.20               \n",
      "Pygments               2.7.3              \n",
      "pyparsing              2.4.7              \n",
      "pyrsistent             0.17.3             \n",
      "python-dateutil        2.8.1              \n",
      "pytz                   2020.4             \n",
      "pywin32                300                \n",
      "pywinpty               0.5.7              \n",
      "pyzmq                  20.0.0             \n",
      "qtconsole              5.0.1              \n",
      "QtPy                   1.9.0              \n",
      "requests               2.25.1             \n",
      "requests-oauthlib      1.3.0              \n",
      "rsa                    4.6                \n",
      "scipy                  1.5.4              \n",
      "Send2Trash             1.5.0              \n",
      "setuptools             51.1.0.post20201221"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "six                    1.15.0             \n",
      "tensorboard            2.4.0              \n",
      "tensorboard-plugin-wit 1.7.0              \n",
      "tensorflow             1.14.0             \n",
      "tensorflow-estimator   2.4.0              \n",
      "termcolor              1.1.0              \n",
      "terminado              0.9.1              \n",
      "testpath               0.4.4              \n",
      "tf-slim                1.1.0              \n",
      "tornado                6.1                \n",
      "traitlets              5.0.5              \n",
      "typing-extensions      3.7.4.3            \n",
      "urllib3                1.26.2             \n",
      "wcwidth                0.2.5              \n",
      "webencodings           0.5.1              \n",
      "Werkzeug               1.0.1              \n",
      "wheel                  0.36.2             \n",
      "widgetsnbextension     3.5.1              \n",
      "wrapt                  1.12.1             \n",
      "zipp                   3.4.0              \n",
      "Collecting tensorflow==1.14\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/08/25e47a53692c2e0dcd2211a493ddfe9007a5cd92e175d6dffa6169a0b392/tensorflow-1.14.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting wrapt>=1.11.1 (from tensorflow==1.14)\n",
      "Collecting wheel>=0.26 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/63/39d04c74222770ed1589c0eaba06c05891801219272420b40311cd60c880/wheel-0.36.2-py2.py3-none-any.whl\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting six>=1.10.0 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/4a/e3/5568a6987645599579667f34606f098bb9be9c7709567eaeb62009da9b52/grpcio-1.34.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/5f/a5/24db9dd5c4a8b6c8e495289f17c28e55601769798b0e2e5a5aeb2abd247b/numpy-1.19.4-cp37-cp37m-win_amd64.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/f4/089025cfa3ee62f89cae73f4d36daf46f339c6df61becfe4b24f3aeb3c0d/protobuf-3.14.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.14)\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras-applications>=1.0.6->tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/53/c2/77bd81922264520b492bd7bfd1a51a845bc1187445408a7a83db284fd566/h5py-3.1.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/6e/77/e921ae5c370698762cf645797f42e6d4d7e679f705a8a9697234591808aa/setuptools-51.1.0.post20201221-py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl\n",
      "Collecting cached-property; python_version < \"3.8\" (from h5py->keras-applications>=1.0.6->tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/7a/85/ac225e35048e050a6351b6f1251cdb2b6060092f2c6840aff1d6319941b1/importlib_metadata-3.3.0-py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\" (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Installing collected packages: wrapt, wheel, tensorflow-estimator, numpy, six, keras-preprocessing, absl-py, grpcio, gast, cached-property, h5py, keras-applications, protobuf, setuptools, werkzeug, zipp, typing-extensions, importlib-metadata, markdown, tensorboard, google-pasta, termcolor, astor, tensorflow\n",
      "Successfully installed absl-py-0.11.0 astor-0.8.1 cached-property-1.5.2 gast-0.4.0 google-pasta-0.2.0 grpcio-1.34.0 h5py-3.1.0 importlib-metadata-3.3.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.4 protobuf-3.14.0 setuptools-51.1.0.post20201221 six-1.15.0 tensorboard-2.4.0 tensorflow-1.14.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.0\n"
     ]
    }
   ],
   "source": [
    "#installing tf\n",
    "!pip install --upgrade --ignore-installed  tensorflow==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (8.0.1)\n",
      "Requirement already satisfied: lxml in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (4.6.2)\n",
      "Requirement already satisfied: jupyter in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: matplotlib in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: cython in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (0.29.21)\n",
      "Requirement already satisfied: opencv-python in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (4.4.0.46)\n",
      "Requirement already satisfied: nbconvert in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jupyter) (6.0.7)\n",
      "Requirement already satisfied: ipykernel in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jupyter) (5.4.2)\n",
      "Requirement already satisfied: jupyter-console in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jupyter) (6.2.0)\n",
      "Requirement already satisfied: ipywidgets in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jupyter) (7.5.1)\n",
      "Requirement already satisfied: notebook in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jupyter) (6.1.5)\n",
      "Requirement already satisfied: qtconsole in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jupyter) (5.0.1)\n",
      "Requirement already satisfied: numpy>=1.15 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib) (1.19.4)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: jupyterlab-pygments in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (1.4.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (5.0.5)\n",
      "Requirement already satisfied: bleach in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (3.2.1)\n",
      "Requirement already satisfied: testpath in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (0.4.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (5.0.8)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: jinja2>=2.4 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (2.11.2)\n",
      "Requirement already satisfied: jupyter-core in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (4.7.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbconvert->jupyter) (2.7.3)\n",
      "Requirement already satisfied: ipython>=5.0.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipykernel->jupyter) (7.19.0)\n",
      "Requirement already satisfied: jupyter-client in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipykernel->jupyter) (6.1.7)\n",
      "Requirement already satisfied: tornado>=4.2 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jupyter-console->jupyter) (3.0.8)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipywidgets->jupyter) (3.5.1)\n",
      "Requirement already satisfied: Send2Trash in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from notebook->jupyter) (0.9.1)\n",
      "Requirement already satisfied: argon2-cffi in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from notebook->jupyter) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from notebook->jupyter) (0.9.0)\n",
      "Requirement already satisfied: pyzmq>=17 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from notebook->jupyter) (20.0.0)\n",
      "Requirement already satisfied: ipython-genutils in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: qtpy in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from qtconsole->jupyter) (1.9.0)\n",
      "Requirement already satisfied: six in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: packaging in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from bleach->nbconvert->jupyter) (20.8)\n",
      "Requirement already satisfied: webencodings in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbformat>=4.4->nbconvert->jupyter) (3.2.0)\n",
      "Requirement already satisfied: async-generator in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.4.3)\n"
     ]
    }
   ],
   "source": [
    "# installing dependenies for project\n",
    "!pip install pillow lxml jupyter matplotlib cython opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=0.23 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jinja2>=2.4->nbconvert->jupyter) (1.1.1)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jupyter-core->nbconvert->jupyter) (300)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.4.4)\n",
      "Requirement already satisfied: decorator in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (51.1.0.post20201221)\n",
      "Requirement already satisfied: backcall in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: wcwidth in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.5)\n",
      "Requirement already satisfied: pywinpty>=0.5; os_name == \"nt\" in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from terminado>=0.8.3->notebook->jupyter) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from argon2-cffi->notebook->jupyter) (1.14.4)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (20.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.3.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter) (0.7.1)\n",
      "Requirement already satisfied: pycparser in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.20)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.4.0)\n",
      "\n",
      "7-Zip 4.57  Copyright (c) 1999-2007 Igor Pavlov  2007-12-06\n",
      "\n",
      "Usage: 7z <command> [<switches>...] <archive_name> [<file_names>...]\n",
      "       [<@listfiles...>]\n",
      "\n",
      "<Commands>\n",
      "  a: Add files to archive\n",
      "  b: Benchmark\n",
      "  d: Delete files from archive\n",
      "  e: Extract files from archive (without using directory names)\n",
      "  l: List contents of archive\n",
      "  t: Test integrity of archive\n",
      "  u: Update files to archive\n",
      "  x: eXtract files with full paths\n",
      "<Switches>\n",
      "  -ai[r[-|0]]{@listfile|!wildcard}: Include archives\n",
      "  -ax[r[-|0]]{@listfile|!wildcard}: eXclude archives\n",
      "  -bd: Disable percentage indicator\n",
      "  -i[r[-|0]]{@listfile|!wildcard}: Include filenames\n",
      "  -m{Parameters}: set compression Method\n",
      "  -o{Directory}: set Output directory\n",
      "  -p{Password}: set Password\n",
      "  -r[-|0]: Recurse subdirectories\n",
      "  -scs{UTF-8 | WIN | DOS}: set charset for list files\n",
      "  -sfx[{name}]: Create SFX archive\n",
      "  -si[{name}]: read data from stdin\n",
      "  -slt: show technical information for l (List) command\n",
      "  -so: write data to stdout\n",
      "  -ssc[-]: set sensitive case mode\n",
      "  -ssw: compress shared files\n",
      "  -t{Type}: Set type of archive\n",
      "  -v{Size}[b|k|m|g]: Create volumes\n",
      "  -u[-][p#][q#][r#][x#][y#][z#][!newArchiveName]: Update options\n",
      "  -w[{path}]: assign Work directory. Empty path means a temporary directory\n",
      "  -x[r[-|0]]]{@listfile|!wildcard}: eXclude filenames\n",
      "  -y: assume Yes on all queries\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['PATH'] += ';C:\\Program Files (x86)\\7-Zip'\n",
    "\n",
    "!\"C:\\Program Files (x86)\\7-Zip\\7z.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning from previous installation \n",
    "\n",
    "# uncomment here if smth failed to return to project's root folder\n",
    "# %cd ..\n",
    "# %pwd\n",
    "\n",
    "import shutil\n",
    "shutil.rmtree('tf', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\tf\\models\\research\\tf\n",
      "^C\n",
      "\n",
      "7-Zip 4.57  Copyright (c) 1999-2007 Igor Pavlov  2007-12-06\n",
      "\n",
      "Processing archive: .\\protoc.zip\n",
      "\n",
      "Extracting  include\n",
      "Extracting  include\\google\n",
      "Extracting  include\\google\\protobuf\n",
      "Extracting  include\\google\\protobuf\\wrappers.proto\n",
      "Extracting  include\\google\\protobuf\\field_mask.proto\n",
      "Extracting  include\\google\\protobuf\\api.proto\n",
      "Extracting  include\\google\\protobuf\\struct.proto\n",
      "Extracting  include\\google\\protobuf\\descriptor.proto\n",
      "Extracting  include\\google\\protobuf\\timestamp.proto\n",
      "Extracting  include\\google\\protobuf\\compiler\n",
      "Extracting  include\\google\\protobuf\\compiler\\plugin.proto\n",
      "Extracting  include\\google\\protobuf\\empty.proto\n",
      "Extracting  include\\google\\protobuf\\any.proto\n",
      "Extracting  include\\google\\protobuf\\source_context.proto\n",
      "Extracting  include\\google\\protobuf\\type.proto\n",
      "Extracting  include\\google\\protobuf\\duration.proto\n",
      "Extracting  bin\n",
      "Extracting  bin\\protoc.exe\n",
      "Extracting  readme.txt\n",
      "\n",
      "Everything is Ok\n",
      "\n",
      "Folders: 5\n",
      "Files: 14\n",
      "Size:       3854360\n",
      "Compressed: 1474788\n"
     ]
    }
   ],
   "source": [
    "# installing object detection \n",
    "\n",
    "!mkdir \"tf\"\n",
    "%cd \"tf\"\n",
    "\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "!python -c \"from urllib.request import urlretrieve; urlretrieve('https://github.com/protocolbuffers/protobuf/releases/download/v3.14.0/protoc-3.14.0-win64.zip', 'protoc.zip')\"\n",
    "!\"C:\\Program Files (x86)\\7-Zip\\7z.exe\" x .\\protoc.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] Не удается найти указанный файл: 'models/research/'\n",
      "E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\tf\\models\\research\\tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‘ЁбвҐ¬Ґ ­Ґ г¤ Ґвбп ­ ©вЁ гЄ § ­­л© Їгвм.\n",
      "\"rm\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd models/research/\n",
    "!..\\..\\bin\\protoc.exe object_detection/protos/*.proto --python_out=.\n",
    "!rm -r include; rm -r bin; rm -r protoc.zip\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68StUELaQPS2",
    "outputId": "eb4c653c-6485-4116-c6e8-12894568e552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.19.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow 1.14.0 has requirement tensorboard<1.15.0,>=1.14.0, but you'll have tensorboard 2.4.0 which is incompatible.\n",
      "tensorflow 1.14.0 has requirement tensorflow-estimator<1.15.0rc0,>=1.14.0rc0, but you'll have tensorflow-estimator 2.4.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://files.pythonhosted.org/packages/e8/c8/9a55f91d4a08652095bdbdfb3b2bb98e7d61146ef3341e3744bc3e7d7021/numpy-1.19.3-cp37-cp37m-win_amd64.whl\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.19.4\n",
      "Requirement already satisfied: tf_slim in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: lvis in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from tf_slim) (0.11.0)\n",
      "Requirement already satisfied: cycler>=0.10.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (0.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (4.4.0.46)\n",
      "Requirement already satisfied: Cython>=0.29.12 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (0.29.21)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (3.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from lvis) (1.19.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib>=3.1.1->lvis) (8.0.1)\n",
      "Requirement already satisfied: pandas in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: six>=1.5 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scipy in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from scipy) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "# !apt-get update && apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "!pip install --upgrade --ignore-installed numpy==1.19.3\n",
    "\n",
    "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "!pip install tf_slim lvis\n",
    "\n",
    "!pip install pandas\n",
    "\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools-windows\n",
      "  Downloading https://files.pythonhosted.org/packages/aa/14/8f3690a2ba537e28b05fa945bd35380290f8d0396158ed639a804fd864ad/pycocotools_windows-2.0.0.2-cp37-cp37m-win_amd64.whl (83kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from pycocotools-windows) (51.1.0.post20201221)\n",
      "Requirement already satisfied: cython>=0.27.3 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from pycocotools-windows) (0.29.21)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from pycocotools-windows) (3.3.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in e:\\pycharmproject\\rep\\venv\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools-windows) (1.15.0)\n",
      "Installing collected packages: pycocotools-windows\n",
      "Successfully installed pycocotools-windows-2.0.0.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install -qq pycocotools\n",
    "#!pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
    "!pip install pycocotools-windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\PycharmProject\\\\Rep\\\\50. Нейросети\\\\dolgonosiki-dataset',\n",
       " 'E:\\\\tensorflow\\\\models\\\\research\\\\slim',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\scripts\\\\python37.zip',\n",
       " 'C:\\\\Program Files\\\\Python37\\\\DLLs',\n",
       " 'C:\\\\Program Files\\\\Python37\\\\lib',\n",
       " 'C:\\\\Program Files\\\\Python37',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv',\n",
       " '',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\pip-19.0.3-py3.7.egg',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\win32',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\User\\\\.ipython']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\tf\\models\\research\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# uncomment to skip installing 🐱\n",
    "\n",
    "%cd ..\n",
    "# %cd tf\\models\\research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\PycharmProject\\\\Rep\\\\50. Нейросети\\\\dolgonosiki-dataset',\n",
       " 'E:\\\\tensorflow\\\\models\\\\research\\\\slim',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\scripts\\\\python37.zip',\n",
       " 'C:\\\\Program Files\\\\Python37\\\\DLLs',\n",
       " 'C:\\\\Program Files\\\\Python37\\\\lib',\n",
       " 'C:\\\\Program Files\\\\Python37',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv',\n",
       " '',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\pip-19.0.3-py3.7.egg',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\win32',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'e:\\\\pycharmproject\\\\rep\\\\venv\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\User\\\\.ipython',\n",
       " 'E:\\\\PycharmProject\\\\Rep\\\\50. Нейросети\\\\dolgonosiki-dataset\\\\tf\\\\models\\\\research',\n",
       " 'E:\\\\PycharmProject\\\\Rep\\\\50. Нейросети\\\\dolgonosiki-dataset\\\\tf\\\\models\\\\research\\\\object_detection\\\\utils']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# addinginstalled libraries to PYTHONPATH\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), 'object_detection\\\\utils'))\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\n"
     ]
    }
   ],
   "source": [
    "# Back to start destination\n",
    "\n",
    "%cd ..\\..\\.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMlXJ2yIV8e7"
   },
   "source": [
    "## Choosing a pre training model\n",
    "The model used for this project is `ssd_mobilenet_v2_coco`.\n",
    "Check other models from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md).\n",
    "\n",
    "Because the interestes of this project is to interfere on real time video, i am chosing a model that has a high inference speed `(ms)` with relativly high `mAP` on COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Some models to train on\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
    "    },\n",
    "    'rfcn_resnet101': {\n",
    "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
    "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select a model in `MODELS_CONFIG`.\n",
    "# I chose ssd_mobilenet_v2 for this project, you could choose any\n",
    "selected_model = 'ssd_mobilenet_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERyocH9U-o2Y"
   },
   "source": [
    "## General imports\n",
    "Other Imports will be done after downloading some packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CEVLeKXh-s23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import cv2 \n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import io\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import shutil\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8QeHvX6gpmC",
    "outputId": "741566ef-0904-4d75-f9f1-c86db425e9cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "#we need tenorflow v 1.14.0, object detection API is removed from tf v 2.0+\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOcbTFEiPBKA"
   },
   "source": [
    "## Downloading and Orgniazing Images and Annotations\n",
    "1. Downloading the images and annotations from the [source](https://sci2s.ugr.es/weapons-detection)  and unziping them\n",
    "2. Creating a directory `(data)` to save some data such as; images, annotation, csv, etc...\n",
    "3. Creating two directories; for the training and testing labels (not the images)\n",
    "4. Randomly splitting our labels into 80% training and 20% testing and moving the splits to their directories: `(train_labels)` & `(test_labels)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kdBz81I0E4d"
   },
   "outputs": [],
   "source": [
    "# == uncomment this if you need to reset all files/folder structure ==\n",
    "# !rm -rf /content\n",
    "# !mkdir /content\n",
    "# %cd /content\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QY-CyUQwyZr",
    "outputId": "2c9db3b7-f715-400c-cb0d-7a744d25a238"
   },
   "outputs": [],
   "source": [
    "#creates a directory for the whole project\n",
    "# !mkdir gun_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHPQQmhm7RLe",
    "outputId": "55996c80-1959-4f23-8b11-22aa49a7ce89"
   },
   "outputs": [],
   "source": [
    "# cd gun_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tp62o3a07UbP",
    "outputId": "4fb26fc3-8a22-497d-a959-f01b22e9343c"
   },
   "outputs": [],
   "source": [
    "# #Training images and annotations\n",
    "\n",
    "# #Source: https://sci2s.ugr.es/weapons-detection\n",
    "\n",
    "\n",
    "# #download the images zip\n",
    "# !wget https://github.com/mewforest/dolgonosiki-dataset/raw/main/images.zip   # <-- 😀 YOUR CUSTOM DATASET IMAGES\n",
    "# # dolgonosik 01.jpg, dolgonosik 02.jpg, ...\n",
    "\n",
    "# #unzip the image file\n",
    "# !unzip -q images.zip\n",
    "\n",
    "# #download the annotations zip\n",
    "# !wget https://github.com/mewforest/dolgonosiki-dataset/raw/main/labels.zip # <-- 😀 YOUR CUSTOM DATASET LABELS (PASCAL VOC)\n",
    "# # dolgonosik 01.xml, dolgonosik 02.xml, ...\n",
    "# #\n",
    "# # You can label your images with labelImg -> https://github.com/tzutalin/labelImg \n",
    "# # \n",
    "# # <?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "# # <annotation>\n",
    "# # <folder>dolgonosik</folder>\n",
    "# # <filename>dolgonosik 124</filename>\n",
    "# # <path>E:\\dolgonosik\\images\\dolgonosik 124.jpg</path>\n",
    "# # <source>\n",
    "# # <database>Unknown</database>\n",
    "# # </source>\n",
    "# # <size>\n",
    "# # <width>480</width>\n",
    "# # <height>360</height>\n",
    "# # <depth>3</depth>\n",
    "# # </size>\n",
    "# # <segmented>0</segmented>\n",
    "# # <object>\n",
    "# # <name>dolgonosik</name>\n",
    "# # <pose>Unspecified</pose>\n",
    "# # <truncated>0</truncated>\n",
    "# # <difficult>0</difficult>\n",
    "# # <bndbox>\n",
    "# # <xmin>36</xmin>\n",
    "# # <ymin>104</ymin>\n",
    "# # <xmax>425</xmax>\n",
    "# # <ymax>309</ymax>\n",
    "# # </bndbox>\n",
    "# # </object>\n",
    "# # </annotation>\n",
    "\n",
    "# #unzip the annotations file\n",
    "# !unzip -q labels.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0czMMeR8GxW",
    "outputId": "893dd74e-fc2e-442f-8e20-e3b8fba46d27"
   },
   "outputs": [],
   "source": [
    "# # creating a directory to store the training and testing data\n",
    "# !mkdir data\n",
    "\n",
    "# # folders for the training and testing data.\n",
    "# !mkdir data/images data/train_labels data/test_labels\n",
    "\n",
    "\n",
    "# # combining the images and annotation in the training folder:\n",
    "# # moves the images to data folder\n",
    "# !mv images/* data/images\n",
    "\n",
    "# # moves the annotations to data folder\n",
    "# !mv labels/* data/train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vv8pmB2D80M7"
   },
   "outputs": [],
   "source": [
    "# # Deleting the zipped and unzipped folders \n",
    "# !rm -rf labels.zip  images.zip images/  labels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUl-XRwPvj4j"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n",
    "# # Moves the first 50 (!!!) labels to the testing dir: `test_labels`\n",
    "# !ls data/train_labels/* | sort -R | head -50 | xargs -I{} mv {} data/test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmvDu-rUHz96",
    "outputId": "55d7021e-dbd6-41cc-80d1-b565a2243aa0"
   },
   "outputs": [],
   "source": [
    "# # 2400 \"images\"(xml) for training\n",
    "# !ls data/train_labels/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8y-1_t7wRJc",
    "outputId": "6cbb4f36-838f-401d-8cce-d786cbf613c4"
   },
   "outputs": [],
   "source": [
    "# # 600 \"images\"(xml) for testing\n",
    "# !ls -1 data/test_labels/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOfuwfPrPSMz"
   },
   "source": [
    "## Preprocessing Images and Labels\n",
    "1. Converting the annotations from xml files to two csv files for each `train_labels/` and `train_labels/`.\n",
    "2. Creating a pbtxt file that specifies the number of class (one class in this case)\n",
    "3. Checking if the annotations for each object are placed within the range of the image width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\gun_detection\\data\n"
     ]
    }
   ],
   "source": [
    "%cd gun_detection/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBHBFpWyEIDI",
    "outputId": "0282c970-246e-44d1-9ab6-70ee783194ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted train_labels xml to csv.\n",
      "Successfully converted test_labels xml to csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
    "\n",
    "#converts the annotations/labels into one csv file for each training and testing labels\n",
    "#creats label_map.pbtxt file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# images extension\n",
    "images_extension = 'jpg'\n",
    "\n",
    "# takes the path of a directory that contains xml files and converts\n",
    "#  them to one csv file.\n",
    "\n",
    "# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n",
    "# note: if the xml file contains more than one box/label, it will create more than one row for the same image. each row contains the info for an individual box. \n",
    "def xml_to_csv(path):\n",
    "  classes_names = []\n",
    "  xml_list = []\n",
    "\n",
    "  for xml_file in glob.glob(path + '/*.xml'):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    for member in root.findall('object'):\n",
    "      classes_names.append(member[0].text)\n",
    "      value = (root.find('filename').text + '.' + images_extension,\n",
    "               int(root.find('size')[0].text),\n",
    "               int(root.find('size')[1].text),\n",
    "               member[0].text,\n",
    "               int(member[4][0].text),\n",
    "               int(member[4][1].text),\n",
    "               int(member[4][2].text),\n",
    "               int(member[4][3].text))\n",
    "      xml_list.append(value)\n",
    "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
    "  classes_names = list(set(classes_names))\n",
    "  classes_names.sort()\n",
    "  return xml_df, classes_names\n",
    "\n",
    "# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n",
    "for label_path in ['train_labels', 'test_labels']:\n",
    "  image_path = os.path.join(os.getcwd(), label_path)\n",
    "  xml_df, classes = xml_to_csv(label_path)\n",
    "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
    "  print(f'Successfully converted {label_path} xml to csv.')\n",
    "\n",
    "# Creating the `label_map.pbtxt` file\n",
    "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
    "\n",
    "pbtxt_content = \"\"\n",
    "\n",
    "#creats a pbtxt file the has the class names.\n",
    "for i, class_name in enumerate(classes):\n",
    "    # display_name is optional.\n",
    "    pbtxt_content = (\n",
    "        pbtxt_content\n",
    "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: 'Dolgonosik'\\n }}\\n\\n\".format(i + 1, class_name)  # <-- 😀 CHANGE HERE DISPLAY NAME :)\n",
    "    )\n",
    "pbtxt_content = pbtxt_content.strip()\n",
    "with open(label_map_path, \"w\") as f:\n",
    "    f.write(pbtxt_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtfjZcD-CCdM",
    "outputId": "393c7a17-452f-4018-f9af-ca3ac45e9fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "    id: 1\n",
      "    name: 'dolgonosik'\n",
      "    display_name: 'Dolgonosik'\n",
      " }\n"
     ]
    }
   ],
   "source": [
    "#checking the pbtxt file\n",
    "!type label_map.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yP8gohagKFXn",
    "outputId": "e2613c1b-d283-43a9-c378-662e19c987ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ’®¬ ў гбва®©бвўҐ E Ё¬ҐҐв ¬ҐвЄг „ЁбЄ®ў®Ґ Їа®бва ­бвў®\n",
      " ‘ҐаЁ©­л© ­®¬Ґа в®¬ : FCC0-9268\n",
      "\n",
      " ‘®¤Ґа¦Ё¬®Ґ Ї ЇЄЁ E:\\PycharmProject\\Rep\\50. ЌҐ©а®бҐвЁ\\dolgonosiki-dataset\\gun_detection\\data\n",
      "\n",
      "25.12.2020  18:42    <DIR>          .\n",
      "25.12.2020  18:42    <DIR>          ..\n",
      "25.12.2020  18:08    <DIR>          images\n",
      "25.12.2020  18:42                77 label_map.pbtxt\n",
      "25.12.2020  18:10    <DIR>          test_labels\n",
      "25.12.2020  18:42             2я518 test_labels.csv\n",
      "25.12.2020  18:10    <DIR>          train_labels\n",
      "25.12.2020  18:42             7я329 train_labels.csv\n",
      "               3 д ©«®ў          9я924 Ў ©в\n",
      "               5 Ї Ї®Є  3я448я466я235я392 Ў ©в бў®Ў®¤­®\n"
     ]
    }
   ],
   "source": [
    "# they are there!\n",
    "! dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4p7J6mFLLZf",
    "outputId": "5cd55085-8974-4fd1-f41f-d8d38806b607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Checking file: train_labels.csv\n",
      "Could not read image None  from  images\\dolgonosik 19.jpg\n",
      "\n",
      "Checked 133 files and realized 1 errors\n",
      "-----\n",
      "[*] Checking file: test_labels.csv\n",
      "\n",
      "Checked 46 files and realized 0 errors\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "#checks if the images box position is placed within the image.\n",
    "\n",
    "#note: while this doesn't checks if the boxes/annotatoins are correctly\n",
    "# placed around the object, Tensorflow will through an error if this occured.\n",
    "# path to images\n",
    "images_path = 'images'\n",
    "\n",
    "#loops over both train_labels and test_labels csv files to do the check\n",
    "# returns the image name where an error is found \n",
    "# return the incorrect attributes; xmin, ymin, xmax, ymax.\n",
    "for CSV_FILE in ['train_labels.csv', 'test_labels.csv']:\n",
    "  with open(CSV_FILE, 'r') as fid:  \n",
    "      print('[*] Checking file:', CSV_FILE) \n",
    "      file = csv.reader(fid, delimiter=',')\n",
    "      first = True \n",
    "      cnt = 0\n",
    "      error_cnt = 0\n",
    "      error = False\n",
    "      for row in file:\n",
    "          if error == True:\n",
    "              error_cnt += 1\n",
    "              error = False         \n",
    "          if first == True:\n",
    "              first = False\n",
    "              continue     \n",
    "          cnt += 1      \n",
    "          name, width, height, xmin, ymin, xmax, ymax = row[0], int(row[1]), int(row[2]), int(row[4]), int(row[5]), int(row[6]), int(row[7])     \n",
    "          path = os.path.join(images_path, name)\n",
    "          img = cv2.imread(path)         \n",
    "          if type(img) == type(None):\n",
    "              error = True\n",
    "              print('Could not read image', img, ' from ', path)\n",
    "              continue     \n",
    "          org_height, org_width = img.shape[:2]     \n",
    "          if org_width != width:\n",
    "              error = True\n",
    "              print('Width mismatch for image: ', name, width, '!=', org_width)     \n",
    "          if org_height != height:\n",
    "              error = True\n",
    "              print('Height mismatch for image: ', name, height, '!=', org_height) \n",
    "          if xmin > org_width:\n",
    "              error = True\n",
    "              print('XMIN > org_width for file', name)  \n",
    "          if xmax > org_width:\n",
    "              error = True\n",
    "              print('XMAX > org_width for file', name)\n",
    "          if ymin > org_height:\n",
    "              error = True\n",
    "              print('YMIN > org_height for file', name)\n",
    "          if ymax > org_height:\n",
    "              error = True\n",
    "              print('YMAX > org_height for file', name)\n",
    "          if error == True:\n",
    "              print('Error for file: %s' % name)\n",
    "              print()\n",
    "      print()\n",
    "      print('Checked %d files and realized %d errors' % (cnt, error_cnt))\n",
    "      print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "vD5luKTsMx7F"
   },
   "outputs": [],
   "source": [
    "#we have only one image with incorrect box position, we could just remove it \n",
    "#removing the image \n",
    "!del \"images\\dolgonosik 19.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ze4z9bW3ZjhC"
   },
   "outputs": [],
   "source": [
    "#removing the entry for it in the csv for that image as well\n",
    "\n",
    "#because we did a random split for the data, we dont know if it ended up being in training or testing\n",
    "# we will remove the image from both.\n",
    "\n",
    "#training\n",
    "#reading the training csv\n",
    "df = pd.read_csv('train_labels.csv')\n",
    "# removing dolgonosik 19.jpg\n",
    "df = df[df['filename'] != 'dolgonosik 19.jpg']\n",
    "#reseting the index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#saving the df\n",
    "df.to_csv('train_labels.csv')\n",
    "\n",
    "\n",
    "#testing\n",
    "#reading the testing csv\n",
    "df = pd.read_csv('test_labels.csv')\n",
    "# removing dolgonosik 19.jpg\n",
    "df = df[df['filename'] != 'dolgonosik 19.jpg']\n",
    "#reseting the index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#saving the df\n",
    "df.to_csv('test_labels.csv')\n",
    "\n",
    "# Just for the memory\n",
    "df = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_tyvKnBP6qD"
   },
   "source": [
    "## Downloading and Preparing Tensorflow model\n",
    "1. Cloning [Tensorflow models](https://github.com/tensorflow/models.git) from the offical git repo. The repo contains the object detection API we are interseted in. \n",
    "2. Compiling the protos and adding folders to the os environment.\n",
    "3. Testing the model builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIxz1GqJQA3f",
    "outputId": "874da480-6be3-43d4-819e-34a04d0f96cc"
   },
   "outputs": [],
   "source": [
    "# # Downlaods Tenorflow\n",
    "# %cd /content/gun_detection/\n",
    "# !git clone --q https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjcAhsxRQ5N1",
    "outputId": "8c431615-f3a4-4d77-e7a6-f53e853c641d"
   },
   "outputs": [],
   "source": [
    "# %cd /content/gun_detection/models/research\n",
    "# #compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n",
    "# !protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# # exports the PYTHONPATH environment variable with the reasearch and slim folders' paths\n",
    "# os.environ['PYTHONPATH'] += ':/content/gun_detection/models/research/:/content/gun_detection/models/research/slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bMNsrwTSJi2"
   },
   "outputs": [],
   "source": [
    "# testing the model builder\n",
    "# !python3 object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9C3L_r4Pi6m"
   },
   "source": [
    "## Generating Tf record\n",
    "- Generating two TFRecords files for the training and testing CSVs.\n",
    "- Tensorflow accepts the data as tfrecords which is a binary file that run fast with low memory usage. Instead of loading the full data into memory, Tenorflow breaks the data into batches using these TFRecords automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\PycharmProject\\\\Rep\\\\50. Нейросети\\\\dolgonosiki-dataset\\\\gun_detection\\\\data'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %cd data\n",
    "%pwd\n",
    "\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nK2unk-9LB_E",
    "outputId": "5149a8fd-ad59-47c5-fb11-0b5326101dbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\gun_detection\\datatrain_labels.record\n",
      "Successfully created the TFRecords: E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\gun_detection\\datatest_labels.record\n"
     ]
    }
   ],
   "source": [
    "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
    "\n",
    "# converts the csv files for training and testing data to two TFRecords files.\n",
    "# places the output in the same directory as the input\n",
    "\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "# %cd /content/gun_detection/models/\n",
    "\n",
    "DATA_BASE_PATH = os.getcwd()\n",
    "image_dir = os.path.join(DATA_BASE_PATH, 'images')\n",
    "\n",
    "# 😀 labelmap.pbtxt\n",
    "#\n",
    "# item {\n",
    "#     id: 1 <--copy this to returning value\n",
    "#     name: 'dolgonosik'  <--copy this to row label\n",
    "#     display_name: 'Dolgonosik'\n",
    "#  }\n",
    "def class_text_to_int(row_label):\n",
    "\t\tif row_label == 'dolgonosik':\n",
    "\t\t\t\treturn 1\n",
    "\t\telse:\n",
    "\t\t\t\tNone\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "\t\tdata = namedtuple('data', ['filename', 'object'])\n",
    "\t\tgb = df.groupby(group)\n",
    "\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "\t\t\t\tencoded_jpg = fid.read()\n",
    "\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "\t\timage = Image.open(encoded_jpg_io)\n",
    "\t\twidth, height = image.size\n",
    "\n",
    "\t\tfilename = group.filename.encode('utf8')\n",
    "\t\timage_format = b'jpg'\n",
    "\t\txmins = []\n",
    "\t\txmaxs = []\n",
    "\t\tymins = []\n",
    "\t\tymaxs = []\n",
    "\t\tclasses_text = []\n",
    "\t\tclasses = []\n",
    "\n",
    "\t\tfor index, row in group.object.iterrows():\n",
    "\t\t\t\txmins.append(row['xmin'] / width)\n",
    "\t\t\t\txmaxs.append(row['xmax'] / width)\n",
    "\t\t\t\tymins.append(row['ymin'] / height)\n",
    "\t\t\t\tymaxs.append(row['ymax'] / height)\n",
    "\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n",
    "\t\t\t\tclasses.append(class_text_to_int(row['class']))\n",
    "\n",
    "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "\t\t\t\t'image/height': dataset_util.int64_feature(height),\n",
    "\t\t\t\t'image/width': dataset_util.int64_feature(width),\n",
    "\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n",
    "\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n",
    "\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
    "\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "\t\t}))\n",
    "\t\treturn tf_example\n",
    "\n",
    "for csv in ['train_labels', 'test_labels']:\n",
    "  writer = tf.io.TFRecordWriter(os.path.join(DATA_BASE_PATH, csv + '.record'))\n",
    "  path = os.path.join(image_dir)\n",
    "  examples = pd.read_csv(os.path.join(DATA_BASE_PATH, csv + '.csv'))\n",
    "  grouped = split(examples, 'filename')\n",
    "  for group in grouped:\n",
    "      tf_example = create_tf_example(group, path)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "  writer.close()\n",
    "  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n",
    "  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1zRJducWs-X",
    "outputId": "5ad478f2-dc91-46eb-b42d-24aff0c36027"
   },
   "outputs": [],
   "source": [
    "# TFRecords are created\n",
    "# !ls -lX /content/gun_detection/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMckMSJqFMyc"
   },
   "source": [
    "## Downloading the Base Model\n",
    "1. Based on the model selecting at the top of this notebook, downloading the model selected and extracting its content.\n",
    "2. Creating a dir to save the model while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\tf\\models\\research\n"
     ]
    }
   ],
   "source": [
    "# %cd /content/gun_detection/models/research\n",
    "%cd ..\\..\\tf\\models\\research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvN9Cw65FQzB",
    "outputId": "3bd4493f-3b1b-4c06-dca1-90423e6dea4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "#selecting the model\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "\n",
    "#creating the downlaod link for the model selected\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "#the distination folder where the model will be saved\n",
    "fine_tune_dir = os.path.join(os.getcwd(), 'pretrained_model')\n",
    "\n",
    "#checks if the model has already been downloaded\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "#unzipping the file and extracting its content\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# creating an output file to save the model while training\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(fine_tune_dir)):\n",
    "    shutil.rmtree(fine_tune_dir)\n",
    "os.rename(MODEL, fine_tune_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbjXKVMmFk47",
    "outputId": "33d611d1-8d68-4484-b915-c48fa3c95fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\50. ЌҐ©а®бҐвЁ\\dolgonosiki-dataset\\tf\\models\\research\\pretrained_model\n"
     ]
    }
   ],
   "source": [
    "#checking the content of the pretrained model.\n",
    "# this is the directory of the \"fine_tune_checkpoint\" that is used in the config file.\n",
    "!echo {fine_tune_dir}\n",
    "# !ls -alh {fine_tune_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnjQgJZiGAcA"
   },
   "source": [
    "## Configuring the Training Pipeline\n",
    "1. Adding the path for the TFRecords files and pbtxt,batch_size,num_steps,num_classes to the configuration file.\n",
    "2. Adding some Image augmentation.\n",
    "3. Creating a directory to save the model at each checkpoint while training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "az14XVo31Ujp",
    "outputId": "cefdec26-25b8-4157-89a9-df1a659b95b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\PycharmProject\\\\Rep\\\\50. Нейросети\\\\dolgonosiki-dataset\\\\tf\\\\models\\\\research\\\\object_detection\\\\samples\\\\configs\\\\ssd_mobilenet_v2_coco.config'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#the path to the folder containing all the sample config files\n",
    "CONFIG_BASE = os.path.join(os.getcwd(), \"object_detection\\\\samples\\\\configs\")\n",
    "\n",
    "#path to the specified model's config file\n",
    "model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n",
    "model_pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\PycharmProject\\\\Rep\\\\50. Нейросети\\\\dolgonosiki-dataset\\\\tf\\\\models\\\\research'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VT3m6pbXpN_M",
    "outputId": "8943ebf0-3901-45a2-ece7-05b3f5f245e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
      "# Users should configure the fine_tune_checkpoint field in the train config as\n",
      "# well as the label_map_path and input_path fields in the train_input_reader and\n",
      "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
      "# should be configured.\n",
      "\n",
      "model {\n",
      "  ssd {\n",
      "    num_classes: 90\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      ssd_anchor_generator {\n",
      "        num_layers: 6\n",
      "        min_scale: 0.2\n",
      "        max_scale: 0.95\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        aspect_ratios: 3.0\n",
      "        aspect_ratios: 0.3333\n",
      "      }\n",
      "    }\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 300\n",
      "        width: 300\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      convolutional_box_predictor {\n",
      "        min_depth: 0\n",
      "        max_depth: 0\n",
      "        num_layers_before_predictor: 0\n",
      "        use_dropout: false\n",
      "        dropout_keep_probability: 0.8\n",
      "        kernel_size: 1\n",
      "        box_code_size: 4\n",
      "        apply_sigmoid_to_scores: false\n",
      "        conv_hyperparams {\n",
      "          activation: RELU_6,\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.00004\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            truncated_normal_initializer {\n",
      "              stddev: 0.03\n",
      "              mean: 0.0\n",
      "            }\n",
      "          }\n",
      "          batch_norm {\n",
      "            train: true,\n",
      "            scale: true,\n",
      "            center: true,\n",
      "            decay: 0.9997,\n",
      "            epsilon: 0.001,\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'ssd_mobilenet_v2'\n",
      "      min_depth: 16\n",
      "      depth_multiplier: 1.0\n",
      "      conv_hyperparams {\n",
      "        activation: RELU_6,\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.00004\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          truncated_normal_initializer {\n",
      "            stddev: 0.03\n",
      "            mean: 0.0\n",
      "          }\n",
      "        }\n",
      "        batch_norm {\n",
      "          train: true,\n",
      "          scale: true,\n",
      "          center: true,\n",
      "          decay: 0.9997,\n",
      "          epsilon: 0.001,\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    loss {\n",
      "      classification_loss {\n",
      "        weighted_sigmoid {\n",
      "        }\n",
      "      }\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      hard_example_miner {\n",
      "        num_hard_examples: 3000\n",
      "        iou_threshold: 0.99\n",
      "        loss_type: CLASSIFICATION\n",
      "        max_negatives_per_positive: 3\n",
      "        min_negatives_per_image: 3\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-8\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  batch_size: 24\n",
      "  optimizer {\n",
      "    rms_prop_optimizer: {\n",
      "      learning_rate: {\n",
      "        exponential_decay_learning_rate {\n",
      "          initial_learning_rate: 0.004\n",
      "          decay_steps: 800720\n",
      "          decay_factor: 0.95\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "      decay: 0.9\n",
      "      epsilon: 1.0\n",
      "    }\n",
      "  }\n",
      "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED/model.ckpt\"\n",
      "  fine_tune_checkpoint_type:  \"detection\"\n",
      "  # Note: The below line limits the training process to 200K steps, which we\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\n",
      "  # never decay). Remove the below line to train indefinitely.\n",
      "  num_steps: 200000\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    ssd_random_crop {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"PATH_TO_BE_CONFIGURED/mscoco_train.record-?????-of-00100\"\n",
      "  }\n",
      "  label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  num_examples: 8000\n",
      "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
      "  # Remove the below line to evaluate indefinitely.\n",
      "  max_evals: 10\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"PATH_TO_BE_CONFIGURED/mscoco_val.record-?????-of-00010\"\n",
      "  }\n",
      "  label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_readers: 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#check the sample config file that is provided by the tf model\n",
    "!type object_detection\\samples\\configs\\ssd_mobilenet_v2_coco.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\50. ЌҐ©а®бҐвЁ\\dolgonosiki-dataset\\tf\\models\\research\\object_detection\\samples\\configs\\ssd_mobilenet_v2_coco.config\n"
     ]
    }
   ],
   "source": [
    "!echo {model_pipline}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "editing the configuration file to add the path for the TFRecords files, pbtxt,batch_size,num_steps,num_classes.\n",
    "any image augmentation, hyperparemeter tunning (drop out, batch normalization... etc) would be editted here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kfsl5CsDGY3-",
    "outputId": "7dc2e639-c5cc-476a-8e37-97894a922f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\tf\\models\\research\\object_detection\\samples\\configs\\ssd_mobilenet_v2_coco.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"{model_pipline}\"\n",
    "model {\n",
    "  ssd {\n",
    "    num_classes: 1 # number of classes to be detected\n",
    "    box_coder {\n",
    "      faster_rcnn_box_coder {\n",
    "        y_scale: 10.0\n",
    "        x_scale: 10.0\n",
    "        height_scale: 5.0\n",
    "        width_scale: 5.0\n",
    "      }\n",
    "    }\n",
    "    matcher {\n",
    "      argmax_matcher {\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "      }\n",
    "    }\n",
    "    similarity_calculator {\n",
    "      iou_similarity {\n",
    "      }\n",
    "    }\n",
    "    anchor_generator {\n",
    "      ssd_anchor_generator {\n",
    "        num_layers: 6\n",
    "        min_scale: 0.2\n",
    "        max_scale: 0.95\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        aspect_ratios: 3.0\n",
    "        aspect_ratios: 0.3333\n",
    "      }\n",
    "    }\n",
    "    # all images will be resized to the below W x H.\n",
    "    image_resizer { \n",
    "      fixed_shape_resizer {\n",
    "        height: 300\n",
    "        width: 300\n",
    "      }\n",
    "    }\n",
    "    box_predictor {\n",
    "      convolutional_box_predictor {\n",
    "        min_depth: 0\n",
    "        max_depth: 0\n",
    "        num_layers_before_predictor: 0\n",
    "        #use_dropout: false\n",
    "        use_dropout: true # to counter over fitting. you can also try tweaking its probability below\n",
    "        dropout_keep_probability: 0.8\n",
    "        kernel_size: 1\n",
    "        box_code_size: 4\n",
    "        apply_sigmoid_to_scores: false\n",
    "        conv_hyperparams {\n",
    "          activation: RELU_6,\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "            # weight: 0.00004\n",
    "            weight: 0.001 # higher regularizition to counter overfitting\n",
    "          }\n",
    "          }\n",
    "          initializer {\n",
    "            truncated_normal_initializer {\n",
    "              stddev: 0.03\n",
    "              mean: 0.0\n",
    "            }\n",
    "          }\n",
    "          batch_norm {\n",
    "            train: true,\n",
    "            scale: true,\n",
    "            center: true,\n",
    "            decay: 0.9997,\n",
    "            epsilon: 0.001,\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: 'ssd_mobilenet_v2'\n",
    "      min_depth: 16\n",
    "      depth_multiplier: 1.0\n",
    "      conv_hyperparams {\n",
    "        activation: RELU_6,\n",
    "        regularizer {\n",
    "          l2_regularizer {\n",
    "            # weight: 0.00004\n",
    "            weight: 0.001 # higher regularizition to counter overfitting\n",
    "          }\n",
    "        }\n",
    "        initializer {\n",
    "          truncated_normal_initializer {\n",
    "            stddev: 0.03\n",
    "            mean: 0.0\n",
    "          }\n",
    "        }\n",
    "        batch_norm {\n",
    "          train: true,\n",
    "          scale: true,\n",
    "          center: true,\n",
    "          decay: 0.9997,\n",
    "          epsilon: 0.001,\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    loss {\n",
    "      classification_loss {\n",
    "        weighted_sigmoid {\n",
    "        }\n",
    "      }\n",
    "      localization_loss {\n",
    "        weighted_smooth_l1 {\n",
    "        }\n",
    "      }\n",
    "      hard_example_miner {\n",
    "        num_hard_examples: 3000 \n",
    "        iou_threshold: 0.95\n",
    "        loss_type: CLASSIFICATION\n",
    "        max_negatives_per_positive: 3\n",
    "        min_negatives_per_image: 3\n",
    "      }\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }\n",
    "    normalize_loss_by_num_matches: true\n",
    "    post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 1e-8\n",
    "        iou_threshold: 0.6\n",
    "        \n",
    "        #adjust this to the max number of objects per class. \n",
    "        # ex, in my case, i have one pistol in most of the images.\n",
    "        # . there are some images with more than one up to 16.\n",
    "        max_detections_per_class: 60\n",
    "        # max number of detections among all classes. I have 1 class only so\n",
    "        max_total_detections: 60\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_config: {\n",
    "  batch_size: 16 # training batch size\n",
    "  optimizer {\n",
    "    rms_prop_optimizer: {\n",
    "      learning_rate: {\n",
    "        exponential_decay_learning_rate {\n",
    "          initial_learning_rate: 0.003\n",
    "          decay_steps: 800720\n",
    "          decay_factor: 0.95\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.9\n",
    "      decay: 0.9\n",
    "      epsilon: 1.0\n",
    "    }\n",
    "  }\n",
    "\n",
    "  #the path to the pretrained model. \n",
    "  fine_tune_checkpoint: \"E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\tf\\models\\research\\pretrained_model\\model.ckpt\"\n",
    "  fine_tune_checkpoint_type:  \"detection\"\n",
    "  # Note: The below line limits the training process to 200K steps, which we\n",
    "  # empirically found to be sufficient enough to train the pets dataset. This\n",
    "  # effectively bypasses the learning rate schedule (the learning rate will\n",
    "  # never decay). Remove the below line to train indefinitely.\n",
    "  num_steps: 10000 # <-- it was 200000 but we cant wait for this time 😀 OK?\n",
    "  \n",
    "\n",
    "  #data augmentaion is done here, you can remove or add more.\n",
    "  # They will help the model generalize but the training time will increase greatly by using more data augmentation.\n",
    "  # Check this link to add more image augmentation: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n",
    "  \n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_adjust_contrast {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    ssd_random_crop {\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    #path to the training TFRecord\n",
    "    input_path: \"E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\gun_detection\\data\\test_labels.record\"\n",
    "  }\n",
    "  #path to the label map \n",
    "  label_map_path: \"E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\gun_detection\\data\\label_map.pbtxt\"\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "  # the number of images in your \"testing\" data (was 600 but we removed one above :) )\n",
    "  num_examples: 43\n",
    "  # the number of images to disply in Tensorboard while training\n",
    "  num_visualizations: 20\n",
    "\n",
    "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
    "  # Remove the below line to evaluate indefinitely.\n",
    "  #max_evals: 10\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "      \n",
    "    #path to the testing TFRecord\n",
    "    input_path: \"E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\gun_detection\\data\\test_labels.record\"\n",
    "  }\n",
    "  #path to the label map \n",
    "  label_map_path: \"E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\gun_detection\\data\\label_map.pbtxt\"\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "EuXXZLVEG8sO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ЌҐ¤®ЇгбвЁ¬л© Є«оз: \"\".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# where the model will be saved at each checkpoint while training \n",
    "model_dir = 'training/'\n",
    "\n",
    "# !!!!😀 Optionally: remove content in output model directory to fresh start.\n",
    "!del {model_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vAGvftxHu8K"
   },
   "source": [
    "## Tensorboard\n",
    "1. Downlaoding and unzipping Tensorboard\n",
    "2. creating a link to visualize multiple graph while training.\n",
    "\n",
    "\n",
    "notes: \n",
    "  1. Tensorboard will not log any files until the training starts. \n",
    "  2. a max of 20 connection per minute is allowed when using ngrok, you will not be able to access tensorboard while the model is logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Program Files\\Python37\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\Scripts\\tensorboard.exe\\__main__.py\", line 9, in <module>\n",
      "  File \"e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\main.py\", line 59, in run_main\n",
      "    program.get_default_assets_zip_provider())\n",
      "  File \"e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\program.py\", line 144, in __init__\n",
      "    self.plugin_loaders = [make_loader(p) for p in plugins]\n",
      "  File \"e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\program.py\", line 144, in <listcomp>\n",
      "    self.plugin_loaders = [make_loader(p) for p in plugins]\n",
      "  File \"e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\program.py\", line 143, in make_loader\n",
      "    raise ValueError(\"Not a TBLoader or TBPlugin subclass: %s\" % plugin)\n",
      "ValueError: Not a TBLoader or TBPlugin subclass: <class 'tensorboard_plugin_wit.wit_plugin_loader.WhatIfToolPluginLoader'>\n"
     ]
    }
   ],
   "source": [
    "# !tensorboard --logdir={LOG_DIR} --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall tensorboard-plugin-wit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
       "  stacklevel=1)\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
       "e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
       "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
       "Traceback (most recent call last):\n",
       "  File \"C:\\Program Files\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
       "    \"__main__\", mod_spec)\n",
       "  File \"C:\\Program Files\\Python37\\lib\\runpy.py\", line 85, in _run_code\n",
       "    exec(code, run_globals)\n",
       "  File \"e:\\pycharmproject\\rep\\venv\\scripts\\tensorboard.exe\\__main__.py\", line 9, in <module>\n",
       "  File \"e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\main.py\", line 59, in run_main\n",
       "    program.get_default_assets_zip_provider())\n",
       "  File \"e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\program.py\", line 144, in __init__\n",
       "    self.plugin_loaders = [make_loader(p) for p in plugins]\n",
       "  File \"e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\program.py\", line 144, in <listcomp>\n",
       "    self.plugin_loaders = [make_loader(p) for p in plugins]\n",
       "  File \"e:\\pycharmproject\\rep\\venv\\lib\\site-packages\\tensorboard\\program.py\", line 143, in make_loader\n",
       "    raise ValueError(\"Not a TBLoader or TBPlugin subclass: %s\" % plugin)\n",
       "ValueError: Not a TBLoader or TBPlugin subclass: <class 'tensorboard_plugin_wit.wit_plugin_loader.WhatIfToolPluginLoader'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2ucxlc5HxHL",
    "outputId": "25b19e40-3416-45e7-f53c-db3c1e1dd9aa"
   },
   "outputs": [],
   "source": [
    "#downlaoding ngrok to be able to access tensorboard on google colab\n",
    "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "# !unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "-w9ufxr7IAdv"
   },
   "outputs": [],
   "source": [
    "#the logs that are created while training \n",
    "# LOG_DIR = model_dir\n",
    "# get_ipython().system_raw(\n",
    "#     'tensorboard --logdir {} --host localhost --port 6006 &'\n",
    "#     .format(LOG_DIR)\n",
    "# )\n",
    "# get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idsi9zyNIIsr",
    "outputId": "69a67f77-69fa-441c-b150-b514fafbb072"
   },
   "outputs": [],
   "source": [
    "#The link to tensorboard.\n",
    "#works after the training starts.\n",
    "\n",
    "### note: if you didnt get a link as output, rerun this cell and the one above\n",
    "# !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuJcAPZFIfu7"
   },
   "source": [
    "## Training\n",
    "\n",
    "Finally training the model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\projects_local\\dolgonosiki-dataset\\tf\\models\\research\\object_detection\n"
     ]
    }
   ],
   "source": [
    "%cd ..\\research\\object_detection\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.5.4-cp37-cp37m-win_amd64.whl (31.2 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in f:\\projects_local\\dolgonosiki-dataset\\venv\\lib\\site-packages (from scipy) (1.19.4)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\50. Нейросети\\dolgonosiki-dataset\\tf\\models\\research\\object_detection\\samples\\configs\\ssd_mobilenet_v2_coco.config\n",
      "training/\n"
     ]
    }
   ],
   "source": [
    "# %cd object_detection\n",
    "print(model_pipline, model_dir, sep='\\n')\n",
    "\n",
    "model_dir = 'training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R90fIDKPYOA5",
    "outputId": "22668d94-95cd-4d11-a63a-1965557f50ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W1225 19:29:05.455697  4444 model_lib.py:793] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I1225 19:29:05.455697  4444 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1225 19:29:05.455697  4444 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I1225 19:29:05.456701  4444 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I1225 19:29:05.456701  4444 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W1225 19:29:05.456701  4444 model_lib.py:809] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "I1225 19:29:05.456701  4444 model_lib.py:846] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000204F15A8128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I1225 19:29:05.456701  4444 estimator.py:209] Using config: {'_model_dir': 'training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000204F15A8128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x00000204F159F8C8>) includes params argument, but params are not passed to Estimator.\n",
      "W1225 19:29:05.457698  4444 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x00000204F159F8C8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I1225 19:29:05.457698  4444 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I1225 19:29:05.457698  4444 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I1225 19:29:05.457698  4444 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1225 19:29:05.462669  4444 deprecation.py:323] From E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "Windows fatal exception: access violation\n",
      "\n",
      "Current thread 0x0000115c (most recent call first):\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 84 in _preread_check\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 122 in read\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\object_detection\\utils\\label_map_util.py\", line 168 in load_labelmap\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\object_detection\\utils\\label_map_util.py\", line 201 in get_label_map_dict\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\object_detection\\data_decoders\\tf_example_decoder.py\", line 89 in __init__\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\object_detection\\data_decoders\\tf_example_decoder.py\", line 393 in __init__\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\object_detection\\builders\\decoder_builder.py\", line 63 in build\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py\", line 195 in build\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\object_detection\\inputs.py\", line 875 in train_input\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\object_detection\\inputs.py\", line 735 in _train_input_fn\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1113 in _call_input_fn\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1022 in _get_features_and_labels_from_input_fn\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1185 in _train_model_default\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1158 in _train_model\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 367 in train\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 714 in run_local\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 613 in run\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 473 in train_and_evaluate\n",
      "  File \"model_main.py\", line 104 in main\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\absl\\app.py\", line 251 in _run_main\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\absl\\app.py\", line 303 in run\n",
      "  File \"E:\\PycharmProject\\Rep\\venv\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40 in run\n",
      "  File \"model_main.py\", line 108 in <module>\n"
     ]
    }
   ],
   "source": [
    "# !python3 .\\tf\\models\\research\\object_detection\\model_main.py \\\n",
    "!python model_main.py \\\n",
    "    --pipeline_config_path=\"{model_pipline}\" \\\n",
    "    --model_dir=\"{model_dir}\" \\\n",
    "    --alsologtostderr \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPN8liiQc7Ue"
   },
   "source": [
    "## Exporting The Trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upwUdom0lTub",
    "outputId": "233de9aa-5066-4870-8732-0a130e1441e3"
   },
   "outputs": [],
   "source": [
    "#custom directory instead of /content/gun_detection/models/research/fine_tuned_model\n",
    "!mkdir /content/gun_detection/models/research/fine_tuned_model_dolgonosik\n",
    "\n",
    "#the location where the exported model will be saved in.\n",
    "output_directory = '/content/gun_detection/models/research/fine_tuned_model_dolgonosik' # <-- /content/gun_detection/models/research/fine_tuned_model\n",
    "\n",
    "# goes through the model is the training/ dir and gets the last one.\n",
    "# you could choose a specfic one instead of the last\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "\n",
    "#exports the model specifed and inference graph\n",
    "!python /content/gun_detection/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={model_pipline} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "yuxDnGPM_JPL",
    "outputId": "86b8729b-4713-4389-f39d-e6ad0dd9d80a"
   },
   "outputs": [],
   "source": [
    "#downloads the frozen model that is needed for inference\n",
    "files.download(output_directory + '/frozen_inference_graph.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "PTkkaGq5BpYi",
    "outputId": "c73aa8ad-9b3e-4676-f0ca-b6df2c6e55ed"
   },
   "outputs": [],
   "source": [
    "#downlaod the label map\n",
    "files.download(DATA_BASE_PATH + '/label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzoNviX1WtHn"
   },
   "source": [
    "# Checking results\n",
    "Part of code is taken from [this collab](https://colab.research.google.com/drive/1nPlFCpSwWuGE2R5E18qp3oYYBqZazXi1#scrollTo=9b47S_agGGG4)\n",
    "\n",
    "1. Loading model to memory (.pb)\n",
    "2. Loading all labels (.pbtxt)\n",
    "3. Initializing method to load an image\n",
    "4. Initializing method to search objects on image\n",
    "5. Testing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWr3WwzHL2vC"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from matplotlib import pyplot as plt\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "model_file_name =  output_directory + '/frozen_inference_graph.pb'\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(model_file_name, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVNOe0xCXgdd"
   },
   "outputs": [],
   "source": [
    "labels_file_name = DATA_BASE_PATH + '/label_map.pbtxt'\n",
    "\n",
    "label_map = label_map_util.load_labelmap(labels_file_name)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9glaGMTEXpj-",
    "outputId": "2b58fdf6-ad64-429f-cdeb-2fb2dc6f5b48"
   },
   "outputs": [],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjmEMO6IXqZ3"
   },
   "outputs": [],
   "source": [
    "def load_image(image_file_name):\n",
    "    image = Image.open(image_file_name)\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPBHMREYXxU8"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Running object detection \n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "      # Converting from float32 to output dict\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X41aSBwOZ5rZ"
   },
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NojCjAc5Y_hF",
    "outputId": "512f3b8b-7555-4774-b5f8-febe2534a3a1"
   },
   "outputs": [],
   "source": [
    "# Testing model on image\n",
    "\n",
    "!wget https://sadiogorod24.ru/wp-content/uploads/2018/05/%D0%94%D0%BE%D0%BB%D0%B3%D0%BE%D0%BD%D0%BE%D1%81%D0%B8%D0%BA-%D0%BD%D0%B0-%D0%BA%D0%BB%D1%83%D0%B1%D0%BD%D0%B8%D0%BA%D0%B5.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "k1m1KWEmZc3i",
    "outputId": "02ebfbd9-264c-4c5a-b01f-19ab8170aae6"
   },
   "outputs": [],
   "source": [
    "# loading image\n",
    "test_image = load_image('https://sadiogorod24.ru/wp-content/uploads/2018/05/%D0%94%D0%BE%D0%BB%D0%B3%D0%BE%D0%BD%D0%BE%D1%81%D0%B8%D0%BA-%D0%BD%D0%B0-%D0%BA%D0%BB%D1%83%D0%B1%D0%BD%D0%B8%D0%BA%D0%B5.jpg')\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.grid(False)\n",
    "cv2_imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wLWEOfEZ-8c"
   },
   "outputs": [],
   "source": [
    "# Running object detection\n",
    "output_dict = run_inference_for_single_image(test_image, detection_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "ce8jhbuiaFv9",
    "outputId": "15e359cf-6b1c-4bb7-fd10-759f44d47c6b"
   },
   "outputs": [],
   "source": [
    "# shows results\n",
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      test_image,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks'),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=6)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.grid(False)\n",
    "cv2_imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNR3NfkjQf0x"
   },
   "source": [
    "# ADDITIONAL [from article]\n",
    "\n",
    "Camera detection: https://gist.github.com/AlaaSenjab/c223e21e7ce3b0e32bf7ba5a5a37a941#file-live_inference-py "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Долгоносики \"weapon_detection_BL (2020).ipynb\"\"",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
